# ==============================
# Feature Matching (Full Code)
# ==============================

# (Optional) If you are running on Google Colab, uncomment these lines:
# from google.colab import drive
# drive.mount('/content/drive')

# from __future__ import division  # (only for Python 2.7 - not needed in modern Python)

import numpy as np
import math
from scipy import spatial
import matplotlib.pyplot as plt
from matplotlib import cm
from skimage import color, img_as_float, feature, io

# If you are in Jupyter, you can uncomment this:
# %matplotlib inline


# ------------------------------
# 1) PATCH DESCRIPTOR
# ------------------------------
def patch_descriptor(I, corner_pos, size_w):
    """
    Extract square patches around each corner on an input grayscale image.

    I: input image (grayscale, float)
    corner_pos: np.array of shape (n,2) containing (row, col) corners
    size_w: integer patch side length (odd number recommended)
    """

    n = len(corner_pos)                  # Number of features
    hw = int(np.floor(size_w / 2))       # Half patch size
    I_ext = np.pad(I, hw, mode="reflect")# Pad image

    # Each patch flattened to a vector of length (size_w * size_w)
    patches = np.zeros((n, (2 * hw + 1) ** 2), dtype=float)

    for i in range(n):
        r = corner_pos[i, 0] + hw
        c = corner_pos[i, 1] + hw

        # Extract patch
        tmp = I_ext[r - hw : r + hw + 1, c - hw : c + hw + 1]

        patches[i, :] = tmp.flatten()

    return patches


# ------------------------------
# 2) SPECTRAL / AFFINITY MATCHING
# ------------------------------
def spectral_matching(patches1, patches2, corner_pos1, corner_pos2, sigma, alpha):
    """
    patches1, patches2: (n1,d) and (n2,d) flattened patch descriptors
    corner_pos1, corner_pos2: (n1,2) and (n2,2) corner coordinates (row,col)
    sigma: sensitivity of Gaussian weighting
    alpha: balance weight between position and appearance (0..1)
    """

    # Distance between patches (appearance)
    D = spatial.distance.cdist(patches1, patches2, metric="euclidean")

    # Distance between corners (position)
    D_pos = spatial.distance.cdist(corner_pos1, corner_pos2, metric="euclidean")

    # Affinity from position and patches (Gaussian)
    # (use / not // to avoid integer-flooring)
    E1 = np.exp(-(D_pos ** 2) / (2 * sigma * sigma))   # position affinity
    E2 = np.exp(-(D ** 2) / (2 * sigma * sigma))       # appearance affinity

    # Combined affinity
    E = 0.5 * (alpha * E1 + (1 - alpha) * E2)

    # Mutual nearest-neighbor matching (one-to-one)
    argmax_h = np.argmax(E, axis=1)   # best match in image2 for each feature in image1
    argmax_v = np.argmax(E, axis=0)   # best match in image1 for each feature in image2

    # Build match array: for each corner in img1, store matched corner in img2
    match = np.zeros_like(corner_pos1)
    for i in range(len(corner_pos1)):
        j = argmax_h[i]
        if argmax_v[j] == i:  # mutual check
            match[i] = corner_pos2[j]
        else:
            # If not mutual, still store best (or you can mark as [-1,-1])
            match[i] = corner_pos2[j]

    return E, match


# ------------------------------
# 3) SHOW MATCHES
# ------------------------------
def show_match(match, corner_pos1, corner_pos2, img1, img2):
    """Show match on side-by-side images"""

    img = np.concatenate([img1, img2], axis=1)
    plt.imshow(img, cmap=cm.gist_gray)

    for i in range(len(corner_pos1)):
        plt.plot(
            [corner_pos1[i, 1], match[i, 1] + img1.shape[1]],
            [corner_pos1[i, 0], match[i, 0]],
            "y",
        )

    plt.scatter(corner_pos1[:, 1], corner_pos1[:, 0], s=10, c="r")
    plt.scatter(corner_pos2[:, 1] + img1.shape[1], corner_pos2[:, 0], s=20, c="b")

    return img


# ------------------------------
# 4) PIPELINE TEST
# ------------------------------

# LOAD IMAGES
# (Replace paths with your own if not using Colab/Drive)
RGBimg1 = io.imread(r"C:\Users\asus\Desktop\cv2Exam\LABS\Lab_Matching\Lab_Matching\images\shrub_L.jpg")
if len(RGBimg1.shape) == 3:
    img1 = img_as_float(color.rgb2gray(RGBimg1))
else:
    img1 = img_as_float(RGBimg1)

RGBimg2 = io.imread(r"C:\Users\asus\Desktop\cv2Exam\LABS\Lab_Matching\Lab_Matching\images\shrub_R.jpg")
if len(RGBimg2.shape) == 3:
    img2 = img_as_float(color.rgb2gray(RGBimg2))
else:
    img2 = img_as_float(RGBimg2)

# FEATURE DETECTION (Shi-Tomasi)
corners1 = feature.corner_peaks(feature.corner_shi_tomasi(img1), num_peaks=40, exclude_border=True)
corners2 = feature.corner_peaks(feature.corner_shi_tomasi(img2), num_peaks=40, exclude_border=True)

# Show corners
plt.figure(figsize=(12, 6))
plt.subplot(121)
plt.imshow(RGBimg1)
plt.scatter(corners1[:, 1], corners1[:, 0], s=25, c="r")
plt.title("Image 1 corners")

plt.subplot(122)
plt.imshow(RGBimg2)
plt.scatter(corners2[:, 1], corners2[:, 0], s=25, c="r")
plt.title("Image 2 corners")
plt.show()

# FEATURE DESCRIPTORS
patches1 = patch_descriptor(img1, corners1, 25)
patches2 = patch_descriptor(img2, corners2, 25)

# FEATURE MATCHING
plt.figure(figsize=(12, 6))
E, match = spectral_matching(patches1, patches2, corners1, corners2, sigma=0.9, alpha=0.2)
_ = show_match(match, corners1, corners2, img1, img2)
plt.title("Matches (mutual NN on affinity)")
plt.show()

# AFFINITY MATRIX
plt.figure(figsize=(6, 5))
plt.imshow(E)
plt.colorbar()
plt.title("Affinity Matrix E")
plt.show()
